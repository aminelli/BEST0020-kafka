version: '3.8'

services:
  spark-master:
    image: spark
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master Port
      - "4040:4040"  # Spark Application Web UI
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    command: >
      bash -c "
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      --host spark-master
      --port 7077
      --webui-port 8080
      "
    networks:
      - spark-network
    volumes:
      - ./data:/opt/spark-data
      - ./apps:/opt/spark-apps

  spark-worker-01:
    image: spark
    container_name: spark-worker-01
    hostname: spark-worker-01
    ports:
      - "8081:8081"  # Worker Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    command: >
      bash -c "
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --webui-port 8081
      --cores 2
      --memory 2g
      "
    depends_on:
      - spark-master
    networks:
      - spark-network
    volumes:
      - ./data:/opt/spark-data
      - ./apps:/opt/spark-apps

  spark-worker-02:
    image: apache/spark:3.5.0
    container_name: spark-worker-02
    hostname: spark-worker-02
    ports:
      - "8082:8082"  # Worker Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    command: >
      bash -c "
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --webui-port 8082
      --cores 2
      --memory 2g
      "
    depends_on:
      - spark-master
    networks:
      - spark-network
    volumes:
      - ./data:/opt/spark-data
      - ./apps:/opt/spark-apps

  # Opzionale: Spark History Server per visualizzare job completati
  spark-history-server:
    image: spark
    container_name: spark-history-server
    hostname: spark-history-server
    ports:
      - "18080:18080"
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark-events
    command: >
      bash -c "
      mkdir -p /opt/spark-events &&
      /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
      "
    networks:
      - spark-network
    volumes:
      - ./spark-events:/opt/spark-events

jupiter:
    image: quay.io/jupyter/pyspark-notebook
    hostname: jupiter
    container_name: jupiter
    ports:
      - 8888:8888
    environment:
      - TINI_SUBREAPER=true  # equivalente a -e TINI_SUBREAPER=true
    networks:
      - spark-network
    volumes:
      - ./scripts:/home/jovyan

networks:
  spark-network:
    driver: bridge

volumes:
  spark-data:
  spark-apps:
  spark-events: